# RSAC Training Configuration
# Based on research findings for drone target tracking

experiment:
  name: "drone_tracking_rsac"
  seed: 42
  device: "cuda"  # cuda, cpu, or mps
  log_dir: "logs"
  checkpoint_dir: "checkpoints"
  save_frequency: 10000  # steps

# Network architecture (from research: GRU 64x2 optimal for embedded)
network:
  obs_dim: 12  # [target_xyz, drone_vel_xyz, prev_action_xyz]
  action_dim: 3  # [vx, vy, vz] velocity commands
  hidden_dim: 64  # GRU hidden dimension
  gru_layers: 2  # Number of GRU layers
  mlp_hidden_dims: [256, 256]  # MLP after GRU
  use_shared_encoder: true  # RSAC-Share (2x faster, -40% memory)

# RSAC algorithm parameters
rsac:
  gamma: 0.99  # Discount factor
  tau: 0.005  # Target network soft update rate
  alpha: 0.2  # Temperature (entropy coefficient)
  auto_tune_alpha: true  # Automatic entropy tuning
  target_entropy: -3.0  # Target entropy (negative action_dim)
  
  # Learning rates
  actor_lr: 0.0003
  critic_lr: 0.0003
  alpha_lr: 0.0003
  
  # Replay buffer
  buffer_capacity: 1000  # Number of episodes
  batch_size: 16  # Episodes per batch
  chunk_length: 50  # BPTT chunk length
  chunk_overlap: 10  # Overlap between chunks
  
  # Training
  total_steps: 1000000  # Total training steps
  warmup_steps: 10000  # Random policy warmup
  updates_per_step: 1  # Gradient updates per env step
  gradient_clip: 0.5  # Max gradient norm

# Environment settings
environment:
  max_episode_steps: 1000  # 50 seconds at 20Hz
  control_frequency: 20  # Hz
  
  # Observation space scaling
  position_scale: 1.0  # meters
  velocity_scale: 1.0  # m/s
  
  # Action space (velocity commands)
  max_velocity: 3.0  # m/s (clipped by safety layer)
  action_scale: 3.0  # Scale network output [-1,1] to [-3,3] m/s

# Reward shaping (from research)
reward:
  type: "dense_to_sparse"  # dense, sparse, dense_to_sparse, shaped
  transition_steps: 200000  # Steps to transition from dense to sparse
  
  # Reward weights (research-validated)
  distance_weight: 1.0
  jerk_weight: 0.1  # CRITICAL for smooth flight
  velocity_weight: 0.05
  acceleration_weight: 0.01
  
  # Bonuses/penalties
  proximity_threshold: 0.5  # meters
  proximity_bonus: 1.0
  lost_target_threshold: 10.0  # meters
  lost_target_penalty: 10.0
  geofence_penalty: 5.0

# Trajectory generation (target motion)
trajectory:
  type: "lissajous_perlin"  # stationary, linear, circular, lissajous, lissajous_perlin
  duration: 60.0  # seconds per episode
  dt: 0.05  # timestep (20 Hz)
  
  # Lissajous parameters (randomized per episode)
  amplitude_x: [1.0, 5.0]  # [min, max] meters
  amplitude_y: [1.0, 5.0]
  amplitude_z: [0.5, 2.0]
  frequency_x: [0.3, 1.5]  # [min, max] Hz
  frequency_y: [0.3, 1.5]
  frequency_z: [0.2, 1.0]
  
  # Perlin noise
  perlin_scale: [0.2, 1.5]  # [min, max] meters
  perlin_octaves: 2
  
  # Spatial bounds (geofence)
  bounds_x: [-10.0, 10.0]
  bounds_y: [-10.0, 10.0]
  bounds_z: [-5.0, -0.5]  # NED: negative is up

# Domain randomization (SIM-TO-REAL CRITICAL)
domain_randomization:
  enabled: true
  randomization_level: 1.0  # 0.0 to 1.0
  
  # Drone physics (from research ranges)
  mass_range: [0.8, 1.2]  # ±20% nominal
  inertia_range: [0.85, 1.15]  # ±15%
  thrust_range: [0.9, 1.1]  # ±10%
  drag_range: [0.5, 2.0]  # 0.5x to 2x
  motor_time_constant_range: [0.01, 0.05]  # seconds
  
  # Sensor noise
  imu_gyro_noise_range: [0.005, 0.02]  # rad/s std
  imu_accel_noise_range: [0.05, 0.2]  # m/s² std
  gps_noise_range: [0.05, 0.2]  # meters std
  barometer_noise_range: [0.02, 0.1]  # meters std
  
  # Communication
  latency_range: [0.02, 0.1]  # 20-100ms
  
  # Environment
  wind_speed_max: 5.0  # m/s
  wind_turbulence: 1.0  # m/s std
  air_density_range: [1.1, 1.3]  # kg/m³
  gravity_range: [0.98, 1.02]  # Sensor calibration variation

# Curriculum learning
curriculum:
  enabled: true
  
  # Stage 1: Stationary targets (0-100K steps)
  stage1:
    steps: 100000
    trajectory_type: "stationary"
    reward_type: "dense"
    distance_weight: 0.5
    jerk_weight: 0.2
    
  # Stage 2: Linear motion (100K-300K steps)
  stage2:
    steps: 200000  # Duration (not cumulative)
    trajectory_type: "linear"
    reward_type: "dense"
    distance_weight: 1.0
    jerk_weight: 0.1
    
  # Stage 3: Complex trajectories (300K+ steps)
  stage3:
    steps: -1  # Infinite (until end of training)
    trajectory_type: "lissajous_perlin"
    reward_type: "dense_to_sparse"
    distance_weight: 1.0
    jerk_weight: 0.1

# Safety layer
safety:
  enabled: true
  enable_fallback_pid: true
  
  # Geofence (spatial limits)
  max_distance_from_home: 20.0  # meters
  min_altitude: 0.5  # meters
  max_altitude: 10.0  # meters
  
  # Velocity limits
  max_horizontal_velocity: 5.0  # m/s
  max_vertical_velocity: 3.0  # m/s
  max_velocity_magnitude: 6.0  # m/s
  max_acceleration: 5.0  # m/s²
  
  # Neural network monitoring
  max_inference_time: 0.05  # seconds (20Hz)
  max_nan_tolerance: 0
  
  # Fallback PID gains
  pid_kp: [1.0, 1.0, 1.5]
  pid_ki: [0.1, 0.1, 0.2]
  pid_kd: [0.5, 0.5, 0.7]

# Logging and evaluation
logging:
  log_interval: 1000  # steps
  eval_interval: 10000  # steps
  eval_episodes: 10
  tensorboard: true
  wandb: false  # Set to true to enable W&B logging
  wandb_project: "drone_tracking_rsac"

# Simulation (Webots + ArduPilot)
simulation:
  use_webots: true
  webots_world: "webots/worlds/drone_tracking.wbt"
  ardupilot_sitl: true
  mavlink_connection: "tcp:127.0.0.1:5760"
  real_time_factor: 1.0  # 1.0 = real-time, >1 = faster

# Deployment (for real drone)
deployment:
  quantization: true  # ONNX quantization (int8)
  target_platform: "jetson"  # jetson, rpi, or cpu
  max_inference_time_ms: 10  # Target inference time
